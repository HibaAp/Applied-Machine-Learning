{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NO442flG3YH0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqWttRNZwTRz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the training and test datasets from CSV files with specified encoding\n",
        "train_df = pd.read_csv('train.csv', encoding='ISO-8859-1')\n",
        "test_df = pd.read_csv('test.csv', encoding='ISO-8859-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OARFNTmtxG2c"
      },
      "outputs": [],
      "source": [
        "# Remove rows with missing values in 'text' or 'sentiment' columns from both datasets\n",
        "train_df = train_df.dropna(subset=['text', 'sentiment'])\n",
        "test_df = test_df.dropna(subset=['text', 'sentiment'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HykaYASqxJWY",
        "outputId": "f154b3fb-4a5a-448e-f6b3-7a9bcca564fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(27480, 3534)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aw2fRAi1sF-b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a dictionary to map sentiment strings to numeric labels\n",
        "label_mapping = {sent: idx for idx, sent in enumerate(['negative', 'neutral', 'positive'])}\n",
        "\n",
        "# Select relevant columns and apply label mapping for training data\n",
        "train_data = train_df[['text', 'sentiment']].copy()\n",
        "train_data['label'] = train_data['sentiment'].map(label_mapping)\n",
        "\n",
        "# Do the same for the test data\n",
        "test_data = test_df[['text', 'sentiment']].copy()\n",
        "test_data['label'] = test_data['sentiment'].map(label_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ud4if0S1HA5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the training data into training and validation sets while preserving label distribution\n",
        "train_split, val_split = train_test_split(\n",
        "    train_data, \n",
        "    test_size=0.2, \n",
        "    stratify=train_data['label'], \n",
        "    random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG9q6O3A0Rlu"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class TextClassificationDataset(Dataset):\n",
        "    def __init__(self, inputs, targets, tokenizer, max_len=128):\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample_text = str(self.inputs[index])\n",
        "        sample_label = int(self.targets[index])\n",
        "\n",
        "        tokenized = self.tokenizer(\n",
        "            sample_text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': tokenized['input_ids'].squeeze(0),\n",
        "            'attention_mask': tokenized['attention_mask'].squeeze(0),\n",
        "            'label': torch.tensor(sample_label, dtype=torch.long)\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFxMClS-2uDB",
        "outputId": "5713afdb-6c96-4556-967f-2646ba23e335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set computation device to GPU if available, otherwise fallback to CPU\n",
        "compute_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "compute_device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "70bdfb23c1374750ae197d05e8bb432a",
            "3121003b2d7e4b85ae806250bf6b30fa",
            "36c5bba41f3b482584ff7beb646d2fc0",
            "ee7c0d250e85421086077d97d3b677f5",
            "a3eca4da214349ed88dd84dc40a70d0b",
            "e5d07d88a18d4c8ea57ef1381ed84351",
            "1cf6974d495d4f41953a4ed68cb8a3cc",
            "ae70f40c77104f9ab9ca8bfc59ba41ff",
            "316a5691cbc74a568830379f42401d4f",
            "95e8caa12f9048729c0324d4d2b322b9",
            "6c77d078349641f98dcd366ae25c52b4",
            "d2a7e34ec5d34033b38bd5edcb503c8d",
            "dd06f78b4ec94cf0bebe17cfa30c96f6",
            "61b4d98e938e45d9a50e52f552da2a42",
            "55457b46b364492cb5b9016a646d9c1d",
            "f9477f60421d40a3893b75963a2c99dc",
            "18421e68057840029f3923365e4080e6",
            "91263b146a3042f7be101554b532ff65",
            "f1069f4249b64cd28d3afa13756e319c",
            "b1b4f72156c846799911c358caf0ad0c",
            "d051b4f735c742df99de511ea09c2328",
            "9eebb8311ccd43faa3a8d5a722cae296",
            "9e34266ba6164a5cafa3dddbe9de6189",
            "add49574bb694cd0a2e4a930f3f1aa54",
            "6c915ffda8f04bb49a2cfb4cde81a34a",
            "bba188e070084f51aaa25073d3860e54",
            "85aaf5db25f548389f5d2da6c58fcceb",
            "1b924f9b81ed4a8fa22e421b97588e23",
            "4cca65ed8a3849049879b7fed915631c",
            "30df07d371da41f585a049f03245ae6b",
            "98890601511a489daa4f591887ae4168",
            "b6ae9f90bd6e4236a7bf20249e4847e6",
            "f774970ba42445f996160fc9e4cf4e67",
            "5655446525574a7f99f0995af3e7deb9",
            "4835c8c9db404121b3caf1484c8dd681",
            "f0d00abfd57e443bb38bc61fad5aee1a",
            "468dca9dc1bb40e680fc8472c24e2365",
            "14e6c33ab225427fbb69acbbb8b8e4f7",
            "bc52c93cab5149989f79caa5dd0fff3c",
            "bc9e15fed2e3401db4f22fc11bbeea59",
            "61fbe9c45238418eb18756859f34f010",
            "dcf3f97549204618bc0392a42a784acc",
            "64e66a567cd24478b795e98c8408ed1f",
            "83eba59bfda34ec3b96b0682be502642"
          ]
        },
        "id": "4r-zY7-D0aO9",
        "outputId": "c01c55df-18b9-415e-dff4-92f00f7b8d5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70bdfb23c1374750ae197d05e8bb432a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2a7e34ec5d34033b38bd5edcb503c8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e34266ba6164a5cafa3dddbe9de6189",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5655446525574a7f99f0995af3e7deb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Define the pretrained model name and load its tokenizer\n",
        "pretrained_model = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
        "\n",
        "# Initialize datasets using the custom dataset class\n",
        "train_set = TextClassificationDataset(\n",
        "    inputs=train_split[\"text\"].tolist(),\n",
        "    targets=train_split[\"label\"].tolist(),\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "val_set = TextClassificationDataset(\n",
        "    inputs=val_split[\"text\"].tolist(),\n",
        "    targets=val_split[\"label\"].tolist(),\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "test_set = TextClassificationDataset(\n",
        "    inputs=test_data[\"text\"].tolist(),\n",
        "    targets=test_data[\"label\"].tolist(),\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDhTDTD03WYd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O58R3llu0sTS"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Specify the name of the pretrained BERT model and load its tokenizer\n",
        "model_identifier = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_identifier)\n",
        "\n",
        "# Construct dataset objects for training, validation, and testing\n",
        "training_data = TextClassificationDataset(\n",
        "    inputs=train_split[\"text\"].tolist(),\n",
        "    targets=train_split[\"label\"].tolist(),\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "validation_data = TextClassificationDataset(\n",
        "    inputs=val_split[\"text\"].tolist(),\n",
        "    targets=val_split[\"label\"].tolist(),\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "testing_data = TextClassificationDataset(\n",
        "    inputs=test_data[\"text\"].tolist(),\n",
        "    targets=test_data[\"label\"].tolist(),\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "624c005373e64e46865d5eaeeda4cc72",
            "00f22222c6404cf682cf5903ffc994ff",
            "5122e911b8eb45258f6be07b89766417",
            "19fa15424bd34071a0dbbc09745b866f",
            "8955306a758b40cfbae780fe0d4eef00",
            "74f4d68de2eb438b8b7dbc84d7e27625",
            "1e54e2c6e9c040b097b1d3d815e6fed0",
            "8b95253cdfca4f38a0b7649964839d71",
            "ca3275033b3f4850af779470572259ae",
            "b095d1361838417eaf23bb72d8f26bf5",
            "ab03752aa18d49dca0c0de5aff9dfa54"
          ]
        },
        "id": "gUGEp9LY1i5C",
        "outputId": "ad4c8b5e-0af3-4c2e-f459-3b759a75cc09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "624c005373e64e46865d5eaeeda4cc72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Load the pretrained model for sequence classification with 3 labels\n",
        "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    pretrained_model,\n",
        "    num_labels=3,\n",
        "    problem_type=\"single_label_classification\"\n",
        ")\n",
        "classification_model.to(compute_device)\n",
        "\n",
        "# Set training hyperparameters\n",
        "num_epochs = 5\n",
        "lr_rate = 3e-5\n",
        "l2_reg = 0.01\n",
        "\n",
        "# Initialize the AdamW optimizer with weight decay\n",
        "optimizer = AdamW(classification_model.parameters(), lr=lr_rate, weight_decay=l2_reg)\n",
        "\n",
        "# Calculate total steps and warmup steps\n",
        "training_steps = len(train_loader) * num_epochs\n",
        "warmup_steps = len(train_loader) // 10  # 10% of steps for warmup phase\n",
        "\n",
        "# Setup learning rate scheduler with warmup\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=training_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9QTpzXM16W6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def train_one_epoch(model, train_loader, optimizer, scheduler, device):\n",
        "    \"\"\"Perform training for a single epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    progress_freq = max(1, len(train_loader) // 5)  # Update progress every 20% of batches\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        # Move batch data to the specified device (GPU/CPU)\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['label'].to(device)\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Perform forward pass\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=targets\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Apply gradient clipping to avoid gradient explosion\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        # Update model parameters\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Display progress\n",
        "        if (step + 1) % progress_freq == 0:\n",
        "            print(f\"Step {step+1}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Return the average loss for the epoch\n",
        "    avg_epoch_loss = total_loss / len(train_loader)\n",
        "    return avg_epoch_loss\n",
        "\n",
        "def evaluate_performance(model, val_loader, device):\n",
        "    \"\"\"Evaluate model performance on the validation set\"\"\"\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            # Move batch data to the specified device (GPU/CPU)\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Perform forward pass\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            # Extract model predictions\n",
        "            logits = outputs.logits\n",
        "            _, predicted = torch.max(logits, dim=1)\n",
        "\n",
        "            # Store the true and predicted labels\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calculate the average validation loss\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = np.mean(np.array(predicted_labels) == np.array(true_labels))\n",
        "\n",
        "    # Calculate precision, recall, and F1-score for each class\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        true_labels, predicted_labels, average=None, zero_division=0\n",
        "    )\n",
        "\n",
        "    return avg_val_loss, accuracy, precision, recall, f1, true_labels, predicted_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqGcOcHY3ydE"
      },
      "outputs": [],
      "source": [
        "# Define sentiment labels and initialize history tracking dictionary\n",
        "sentiment_labels = ['negative', 'neutral', 'positive']\n",
        "training_history = {\n",
        "    'train_loss': [],\n",
        "    'val_loss': [],\n",
        "    'test_loss': [],\n",
        "    'val_accuracy': [],\n",
        "    'test_accuracy': [],\n",
        "    'val_precision': {label: [] for label in sentiment_labels},\n",
        "    'val_recall': {label: [] for label in sentiment_labels},\n",
        "    'val_f1': {label: [] for label in sentiment_labels}\n",
        "}\n",
        "\n",
        "# Monitor GPU memory usage if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    training_history['gpu_memory_usage'] = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMrXo-GS2WmV",
        "outputId": "5dedf8b7-3d2a-4279-ddcf-8690e0367fc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "--------------------------------------------------\n",
            "Batch 110/550 | Loss: 0.7213\n",
            "Batch 220/550 | Loss: 0.4257\n",
            "Batch 330/550 | Loss: 0.6635\n",
            "Batch 440/550 | Loss: 0.3573\n",
            "Batch 550/550 | Loss: 0.5038\n",
            "GPU Memory Usage: 1.78 GB\n",
            "Training Loss: 0.5653\n",
            "Validation Loss: 0.5335 | Validation Accuracy: 0.7833\n",
            "Test Loss: 0.5276 | Test Accuracy: 0.7838\n",
            "\n",
            "Per-class Validation Metrics:\n",
            "--------------------------------------------------\n",
            "Class           Precision  Recall     F1-Score  \n",
            "--------------------------------------------------\n",
            "negative        0.7284       0.8740       0.7946\n",
            "neutral         0.8025       0.6707       0.7307\n",
            "positive        0.8210       0.8468       0.8337\n",
            "--------------------------------------------------\n",
            "\n",
            "Epoch 2/5\n",
            "--------------------------------------------------\n",
            "Batch 110/550 | Loss: 0.2363\n",
            "Batch 220/550 | Loss: 0.2025\n",
            "Batch 330/550 | Loss: 0.3218\n",
            "Batch 440/550 | Loss: 0.4083\n",
            "Batch 550/550 | Loss: 0.7546\n",
            "GPU Memory Usage: 1.78 GB\n",
            "Training Loss: 0.3975\n",
            "Validation Loss: 0.5354 | Validation Accuracy: 0.7926\n",
            "Test Loss: 0.5180 | Test Accuracy: 0.7957\n",
            "\n",
            "Per-class Validation Metrics:\n",
            "--------------------------------------------------\n",
            "Class           Precision  Recall     F1-Score  \n",
            "--------------------------------------------------\n",
            "negative        0.8078       0.7834       0.7954\n",
            "neutral         0.7457       0.7769       0.7610\n",
            "positive        0.8438       0.8212       0.8323\n",
            "--------------------------------------------------\n",
            "\n",
            "Epoch 3/5\n",
            "--------------------------------------------------\n",
            "Batch 110/550 | Loss: 0.2340\n",
            "Batch 220/550 | Loss: 0.2923\n",
            "Batch 330/550 | Loss: 0.2291\n",
            "Batch 440/550 | Loss: 0.1479\n",
            "Batch 550/550 | Loss: 0.2251\n",
            "GPU Memory Usage: 1.78 GB\n",
            "Training Loss: 0.2568\n",
            "Validation Loss: 0.6455 | Validation Accuracy: 0.7880\n",
            "Test Loss: 0.6243 | Test Accuracy: 0.7946\n",
            "\n",
            "Per-class Validation Metrics:\n",
            "--------------------------------------------------\n",
            "Class           Precision  Recall     F1-Score  \n",
            "--------------------------------------------------\n",
            "negative        0.8158       0.7571       0.7853\n",
            "neutral         0.7366       0.7836       0.7594\n",
            "positive        0.8364       0.8218       0.8290\n",
            "--------------------------------------------------\n",
            "\n",
            "Epoch 4/5\n",
            "--------------------------------------------------\n",
            "Batch 110/550 | Loss: 0.0532\n",
            "Batch 220/550 | Loss: 0.1441\n",
            "Batch 330/550 | Loss: 0.1780\n",
            "Batch 440/550 | Loss: 0.1123\n",
            "Batch 550/550 | Loss: 0.0469\n",
            "GPU Memory Usage: 1.78 GB\n",
            "Training Loss: 0.1549\n",
            "Validation Loss: 0.7651 | Validation Accuracy: 0.7833\n",
            "Test Loss: 0.7574 | Test Accuracy: 0.7869\n",
            "\n",
            "Per-class Validation Metrics:\n",
            "--------------------------------------------------\n",
            "Class           Precision  Recall     F1-Score  \n",
            "--------------------------------------------------\n",
            "negative        0.7851       0.7937       0.7894\n",
            "neutral         0.7488       0.7440       0.7464\n",
            "positive        0.8261       0.8247       0.8254\n",
            "--------------------------------------------------\n",
            "\n",
            "Epoch 5/5\n",
            "--------------------------------------------------\n",
            "Batch 110/550 | Loss: 0.1090\n",
            "Batch 220/550 | Loss: 0.1465\n",
            "Batch 330/550 | Loss: 0.0847\n",
            "Batch 440/550 | Loss: 0.0197\n",
            "Batch 550/550 | Loss: 0.0152\n",
            "GPU Memory Usage: 1.78 GB\n",
            "Training Loss: 0.0993\n",
            "Validation Loss: 0.8984 | Validation Accuracy: 0.7838\n",
            "Test Loss: 0.8932 | Test Accuracy: 0.7838\n",
            "\n",
            "Per-class Validation Metrics:\n",
            "--------------------------------------------------\n",
            "Class           Precision  Recall     F1-Score  \n",
            "--------------------------------------------------\n",
            "negative        0.7886       0.7815       0.7850\n",
            "neutral         0.7405       0.7638       0.7520\n",
            "positive        0.8393       0.8119       0.8253\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Training loop over multiple epochs\n",
        "for current_epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {current_epoch+1}/{num_epochs}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Train the model for one epoch\n",
        "    train_epoch_loss = train_one_epoch(model, train_loader, optimizer, scheduler, compute_device)\n",
        "    training_history['train_loss'].append(train_epoch_loss)\n",
        "\n",
        "    # Monitor GPU memory usage if CUDA is available\n",
        "    if torch.cuda.is_available():\n",
        "        allocated_memory = torch.cuda.memory_allocated(0) / 1e9  # Convert to GB\n",
        "        training_history['gpu_memory_usage'].append(allocated_memory)\n",
        "        print(f\"GPU Memory Usage: {allocated_memory:.2f} GB\")\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    val_epoch_loss, val_acc, val_precision, val_recall, val_f1, _, _ = evaluate_performance(model, val_loader, compute_device)\n",
        "    training_history['val_loss'].append(val_epoch_loss)\n",
        "    training_history['val_accuracy'].append(val_acc)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    test_epoch_loss, test_acc, _, _, _, _, _ = evaluate_performance(model, test_loader, compute_device)\n",
        "    training_history['test_loss'].append(test_epoch_loss)\n",
        "    training_history['test_accuracy'].append(test_acc)\n",
        "\n",
        "    # Store per-class precision, recall, and F1-score\n",
        "    for idx, label in enumerate(sentiment_labels):\n",
        "        if idx < len(val_precision):\n",
        "            training_history['val_precision'][label].append(val_precision[idx])\n",
        "            training_history['val_recall'][label].append(val_recall[idx])\n",
        "            training_history['val_f1'][label].append(val_f1[idx])\n",
        "\n",
        "    # Print summary for the current epoch\n",
        "    print(f\"Training Loss: {train_epoch_loss:.4f}\")\n",
        "    print(f\"Validation Loss: {val_epoch_loss:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
        "    print(f\"Test Loss: {test_epoch_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Print detailed metrics for each class\n",
        "    print(\"\\nPer-Class Validation Metrics:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"{'Class':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}\")\n",
        "    print(\"-\" * 50)\n",
        "    for idx, label in enumerate(sentiment_labels):\n",
        "        if idx < len(val_precision):\n",
        "            print(f\"{label:<15} {val_precision[idx]:.4f}{' ':6} {val_recall[idx]:.4f}{' ':6} {val_f1[idx]:.4f}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3U3YJby5TlW",
        "outputId": "04e96189-6d38-49e7-8176-0791b7bd3d22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.80      0.79      1001\n",
            "     neutral       0.75      0.75      0.75      1430\n",
            "    positive       0.84      0.82      0.83      1103\n",
            "\n",
            "    accuracy                           0.78      3534\n",
            "   macro avg       0.79      0.79      0.79      3534\n",
            "weighted avg       0.78      0.78      0.78      3534\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "_, _, test_precision, test_recall, test_f1, true_labels, predicted_labels = evaluate_performance(model, test_loader, compute_device)\n",
        "\n",
        "# Print the final classification report for the test set\n",
        "print(\"Final Classification Report on Test Set:\")\n",
        "print(classification_report(true_labels, predicted_labels, target_names=sentiment_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPxAGw8a2jkR",
        "outputId": "4f1a2cec-1f89-4f32-a8de-37cce3364633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text                                               Prediction\n",
            "---------------------------------------------------------------------------\n",
            "Its absolutely amazing!                                                positive\n",
            "Nothing much to say. Okay okayish feel.                                neutral\n",
            "I regret about my decision.                                            negative\n"
          ]
        }
      ],
      "source": [
        "# Sample texts for prediction\n",
        "sample_texts = [\n",
        "    \"Its absolutely amazing!\",\n",
        "    \"Nothing much to say. Okay okayish feel.\",\n",
        "    \"I regret about my decision.\"\n",
        "]\n",
        "\n",
        "# Display predictions for each text\n",
        "print(f\"{'Text':<50} {'Predicted Sentiment'}\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "for input_text in sample_texts:\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the input text\n",
        "    encoded_input = tokenizer(\n",
        "        input_text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoded_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_input['attention_mask'].to(device)\n",
        "\n",
        "    # Perform inference without updating gradients\n",
        "    with torch.no_grad():\n",
        "        model_outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        probabilities = torch.nn.functional.softmax(model_outputs.logits, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "    # Map prediction to sentiment label\n",
        "    sentiment_mapping = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "    predicted_sentiment = sentiment_mapping[predicted_class.item()]\n",
        "    \n",
        "    # Print the result\n",
        "    print(f\"{input_text:<70} {predicted_sentiment}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgETQxA9Be67"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
